
import aiohttp
import asyncio
import logging
from io import BytesIO
from PIL import Image
from config import IMAGE_MAX_SIZE, IMAGE_QUALITY, HUGGINGFACE_API_KEY

logger = logging.getLogger(__name__)

class ImageGeneratorService:
    """–°–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Hugging Face Inference API"""
    
    # –ú–æ–¥–µ–ª–∏ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
    # 1. FLUX.1-schnell (–ë—ã—Å—Ç—Ä–∞—è, –∫—Ä—É—Ç–∞—è)
    # 2. SDXL (–ù–∞–¥–µ–∂–Ω–∞—è –∫–ª–∞—Å—Å–∏–∫–∞)
    MODEL_FLUX = "black-forest-labs/FLUX.1-schnell"
    MODEL_SDXL = "stabilityai/stable-diffusion-xl-base-1.0"
    
    API_URL = "https://router.huggingface.co/hf-inference/models/"
    
    def __init__(self):
        self.headers = {
            "Authorization": f"Bearer {HUGGINGFACE_API_KEY}"
        }
    
    def _optimize_image(self, image_data: bytes) -> bytes:
        """–°–∂–∞—Ç–∏–µ –∏ —Ä–µ—Å–∞–π–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            img = Image.open(BytesIO(image_data))
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            width, height = img.size
            if width > IMAGE_MAX_SIZE or height > IMAGE_MAX_SIZE:
                ratio = min(IMAGE_MAX_SIZE / width, IMAGE_MAX_SIZE / height)
                new_size = (int(width * ratio), int(height * ratio))
                img = img.resize(new_size, Image.Resampling.LANCZOS)
            
            buffer = BytesIO()
            img.save(buffer, format='JPEG', quality=IMAGE_QUALITY, optimize=True)
            return buffer.getvalue()
        except Exception as e:
            logger.error(f"Optimization error: {e}")
            return image_data

    async def _query(self, session, model, payload):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ HF"""
        url = f"{self.API_URL}{model}"
        try:
            async with session.post(url, headers=self.headers, json=payload, timeout=60) as response:
                content_type = response.headers.get('Content-Type', '')
                
                # –£—Å–ø–µ—Ö
                if response.status == 200 and 'image' in content_type:
                    return await response.read()
                
                # –û—à–∏–±–∫–∞ –∏–ª–∏ –æ–∂–∏–¥–∞–Ω–∏–µ
                try:
                    data = await response.json()
                except:
                    data = {}

                # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≥—Ä—É–∑–∏—Ç—Å—è (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ –¥–ª—è Free Tier)
                if 'error' in data and isinstance(data['error'], str) and 'loading' in data['error'].lower():
                    estimated_time = data.get('estimated_time', 20)
                    logger.info(f"‚è≥ –ú–æ–¥–µ–ª—å {model} –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è. –ñ–¥–µ–º {estimated_time}—Å...")
                    return {"wait": estimated_time}
                    
                logger.warning(f"–û—à–∏–±–∫–∞ API HF {model}: {response.status} - {data}")
                return None
        except Exception as e:
            logger.error(f"–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ HF: {e}")
            return None

    async def generate_image(self, prompt_text: str) -> bytes:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–µ—Ä–µ–±–æ—Ä–æ–º –º–æ–¥–µ–ª–µ–π –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        
        # –£–ª—É—á—à–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –µ–¥—ã
        enhanced_prompt = f"Professional food photography of {prompt_text}, delicious, high quality, 4k, restaurant style, photorealistic"
        
        models_queue = [self.MODEL_FLUX, self.MODEL_SDXL]
        
        async with aiohttp.ClientSession() as session:
            for model in models_queue:
                logger.info(f"üé® –ü—Ä–æ–±—É–µ–º –º–æ–¥–µ–ª—å: {model}")
                
                payload = {
                    "inputs": enhanced_prompt,
                    "parameters": {
                        # Flux –ª—é–±–∏—Ç –º–µ–Ω—å—à–µ —à–∞–≥–æ–≤, SDXL –±–æ–ª—å—à–µ
                        "num_inference_steps": 4 if "FLUX" in model else 25,
                    }
                }
                
                # 3 –ø–æ–ø—ã—Ç–∫–∏ –Ω–∞ –º–æ–¥–µ–ª—å
                for attempt in range(3):
                    result = await self._query(session, model, payload)
                    
                    if isinstance(result, bytes):
                        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª—å—é {model}")
                        return self._optimize_image(result)
                    
                    elif isinstance(result, dict) and "wait" in result:
                        # –£–º–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ
                        wait_time = min(result["wait"], 30)
                        await asyncio.sleep(wait_time)
                        continue
                    
                    else:
                        # –ë—ã—Å—Ç—Ä–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Ä–µ—Ç—Ä–∞–µ–º
                        await asyncio.sleep(1)
            
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª—å—é")
        return None

image_service = ImageGeneratorService()
